1. `np.sort` implements multiple types of sorting algorithms. Users can choose which algorithm to use by specifying the `kind` argument. Do an experiment and try to sort a large array of random numbers using different sorting algorithms and compare their performance. Which algorithm is the fastest? Which algorithm is the slowest?
2. `np.argpartition` uses a bisection algorithm. How is this related to quicksort?
3. How could one use `np.argmax` to implement `np.argmin`? (Hint: think about the relationship between `argmax` and `argmin` and the relationship between `max` and `min`.)
4. Get top 3 values of the following array `[1, 5, 3, 8, 2, 9, 0, 4, 7]`, with the results positioned in the original order of these list (i.e. expecting `[8, 9, 7]`).
5. `np.unique` can return total 4 outputs, i.e. `unique_values, indices, inverse_indices, counts = np.unique(x, return_index=True, return_inverse=True, return_counts=True)`. Discuss, compare, and contrast these outputs. How can we use them to reconstruct the input?
6. Try to sort rows of characters of a 2D matrix by concatenating the characters together and then apply `.sort` function. For example, if the input is `[['h', 'g', 'f'], ['c', 'b', 'a']]`, we first concatenate the characters in each row to get `['cba', 'hgf']` and then apply `.sort` function to get `['cba', 'hgf']`; then split the sorted strings back to characters to get `[['c', 'b', 'a'], ['h', 'g', 'f']]`. How does this approach compare to `lexsort` or `unique` that we implemented?
7. Reverse the following padded sequence by applying hte `reverse_sequence` function. `[[1, 3, 2, 5, 0, 0, 0, 0], [1, 5, 3, 0, 0, 0, 0, 0], [1, 7, 6, 2, 5, 0, 0, 0]]`. Assume `0` is the padding value. Determine the sequence length `seq_lengths` argument based on the input.
8. Consider how we can reverse a `tf.RaggedTensor`, e.g. `tf.ragged.constant([[1, 3, 2, 5], [1, 5, 3], [1, 7, 6, 2, 5]])` (Hint: consider using simple indexing). Can the same idea be applied to `torch.nested.nested_tensor`?
9. Try to implement `gumbel_max_sample_without_replacement` using NumPy.
10. Read the appendix section from the cited reference paper "Review of the Gumbel-max Trick and its Extensions for Discrete Stochasticity in Machine Learning" (http://arxiv.org/abs/ 2110.01515 (2022)), which provided a detailed derivation of the Gumbel-max trick.