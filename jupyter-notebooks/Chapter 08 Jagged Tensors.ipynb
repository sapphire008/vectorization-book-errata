{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34eb473",
   "metadata": {},
   "source": [
    "# Variable-length lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfe7630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:07:48.655365Z",
     "start_time": "2023-11-26T05:07:48.651842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3], [2, 4, 5], [8], []]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python\n",
    "jagged_array = [[1, 3], [2, 4, 5], [8], []]\n",
    "jagged_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49dd6c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:07:48.966093Z",
     "start_time": "2023-11-26T05:07:48.956167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 3]), list([2, 4, 5]), list([8]), list([])], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "jagged_array_np = np.array(\n",
    "    [[1, 3], [2, 4, 5], [8], []], dtype=object\n",
    ")\n",
    "jagged_array_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c00c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:07:51.243550Z",
     "start_time": "2023-11-26T05:07:49.226283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1, 3], [2, 4, 5], [8], []]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "jagged_array_tf = tf.ragged.constant(\n",
    "    [[1, 3], [2, 4, 5], [8], []]\n",
    ")\n",
    "jagged_array_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa74dba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:07:52.162703Z",
     "start_time": "2023-11-26T05:07:51.253170Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jv/p_nfc0852qv0dsy89d4j7kth0000gn/T/ipykernel_62017/2967106059.py:3: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:180.)\n",
      "  jagged_array_torch = torch.nested.nested_tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nested_tensor([\n",
       "  tensor([1, 3]),\n",
       "  tensor([2, 4, 5]),\n",
       "  tensor([8]),\n",
       "  tensor([], dtype=torch.int64)\n",
       "])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "jagged_array_torch = torch.nested.nested_tensor(\n",
    "    [[1, 3], [2, 4, 5], [8], []]\n",
    ")\n",
    "jagged_array_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89e7b8",
   "metadata": {},
   "source": [
    "# Left Align a Sparse Tensor to Represent Ragged Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a53eefe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:08:16.664450Z",
     "start_time": "2023-11-26T05:08:16.655121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1, 3, 2], [4, 6], [1], [], [9, 3, 5, 8], []]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "# RaggedTensor\n",
    "X = tf.ragged.constant([\n",
    "    [1, 3, 2], [4, 6], [1], [], [9, 3, 5, 8], []\n",
    "])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee7d292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:08:25.694964Z",
     "start_time": "2023-11-26T05:08:25.674486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 0]\n",
       " [0 1]\n",
       " [0 2]\n",
       " [1 0]\n",
       " [1 1]\n",
       " [2 0]\n",
       " [4 0]\n",
       " [4 1]\n",
       " [4 2]\n",
       " [4 3]], shape=(10, 2), dtype=int64), values=tf.Tensor([1 3 2 4 6 1 9 3 5 8], shape=(10,), dtype=int32), dense_shape=tf.Tensor([6 4], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to SparseTensor\n",
    "y = X.to_sparse()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0fc28c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:08:33.408285Z",
     "start_time": "2023-11-26T05:08:33.388922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4), dtype=int32, numpy=\n",
       "array([[1, 3, 2, 0],\n",
       "       [4, 6, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [9, 3, 5, 8],\n",
       "       [0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sparse tensor as dense\n",
    "tf.sparse.to_dense(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7a92",
   "metadata": {},
   "source": [
    "# Filtering values in Jagged Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f03de1ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:09:18.005804Z",
     "start_time": "2023-11-26T05:09:17.978074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 0]\n",
       " [0 1]\n",
       " [1 0]\n",
       " [1 1]\n",
       " [2 0]\n",
       " [2 2]\n",
       " [4 1]\n",
       " [4 2]\n",
       " [4 4]\n",
       " [5 0]\n",
       " [5 1]\n",
       " [5 2]], shape=(12, 2), dtype=int64), values=tf.Tensor([1 5 2 4 3 8 2 6 9 7 8 1], shape=(12,), dtype=int32), dense_shape=tf.Tensor([7 5], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "X = [[1, 5], [2, 4, 11], [3, 15, 8], [14], [12, 2, 6, 18, 9], [7, 8, 1], [19]]\n",
    "# Use ragged to sparse to convert to sparse tensor in this example\n",
    "X = tf.ragged.constant(X).to_sparse()\n",
    "# Keep values less than or equal to 10\n",
    "X_filtered = tf.sparse.retain(\n",
    "    X, X.values <= 10\n",
    ")\n",
    "X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6520192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:09:32.435730Z",
     "start_time": "2023-11-26T05:09:32.423865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 5), dtype=int32, numpy=\n",
       "array([[1, 5, 0, 0, 0],\n",
       "       [2, 4, 0, 0, 0],\n",
       "       [3, 0, 8, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 2, 6, 0, 9],\n",
       "       [7, 8, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense\n",
    "tf.sparse.to_dense(X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7341b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May not run on Mac M1 machines\n",
    "import tensorflow_transform as tft\n",
    "X_left_aligned = tft.sparse_tensor_left_align(X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ee5079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:10:52.623748Z",
     "start_time": "2023-11-26T05:10:52.612693Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def sparse_left_align(X: tf.SparseTensor):\n",
    "    # Compute row lengths\n",
    "    row_lengths = X.with_values(tf.ones_like(X.values))\n",
    "    row_lengths = tf.sparse.reduce_sum(row_lengths, axis=1)\n",
    "    row_lengths = tf.cast(row_lengths, tf.int64)\n",
    "    # Create the flattened array enumeration index\n",
    "    array_indices = tf.ragged.range(row_lengths, dtype=tf.int64)\n",
    "    array_indices = array_indices.flat_values\n",
    "    # Recreate the SparseTensor\n",
    "    indices = tf.stack([X.indices[:, 0], array_indices])\n",
    "    indices = tf.transpose(indices)\n",
    "    y = tf.SparseTensor(\n",
    "        indices=indices,\n",
    "        values=X.values,\n",
    "        dense_shape=X.dense_shape,\n",
    "    )\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2478c771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:11:04.224877Z",
     "start_time": "2023-11-26T05:11:04.190259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 0]\n",
       " [0 1]\n",
       " [1 0]\n",
       " [1 1]\n",
       " [2 0]\n",
       " [2 1]\n",
       " [4 0]\n",
       " [4 1]\n",
       " [4 2]\n",
       " [5 0]\n",
       " [5 1]\n",
       " [5 2]], shape=(12, 2), dtype=int64), values=tf.Tensor([1 5 2 4 3 8 2 6 9 7 8 1], shape=(12,), dtype=int32), dense_shape=tf.Tensor([7 5], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_left_aligned = sparse_left_align(X_filtered)\n",
    "X_left_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ea6c89b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:11:12.981000Z",
     "start_time": "2023-11-26T05:11:12.969507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 5), dtype=int32, numpy=\n",
       "array([[1, 5, 0, 0, 0],\n",
       "       [2, 4, 0, 0, 0],\n",
       "       [3, 8, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [2, 6, 9, 0, 0],\n",
       "       [7, 8, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(X_left_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657304bb",
   "metadata": {},
   "source": [
    "# Index to Binary Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02efa561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:11:53.852737Z",
     "start_time": "2023-11-26T05:11:53.823901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=bool, numpy=\n",
       "array([[False,  True,  True,  True, False],\n",
       "       [False, False,  True, False, False],\n",
       "       [ True,  True, False, False,  True]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.ragged.constant([\n",
    "    [1, 3, 2],\n",
    "    [2],\n",
    "    [4, 1, 0]\n",
    "]).to_sparse()\n",
    "\n",
    "tf.sparse.to_indicator(X, vocab_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf5304e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:15:05.424421Z",
     "start_time": "2023-11-26T05:15:05.408906Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def sparse_to_indicator_tf(\n",
    "    X: tf.SparseTensor,\n",
    "    vocab_size: int,\n",
    "    out_dtype: tf.dtypes.DType = tf.float32\n",
    ") -> tf.SparseTensor:\n",
    "    \"\"\"\n",
    "    Convert sparse tensor of indices to vectors of binary indicators\n",
    "\n",
    "    * X: tf.SparseTensor\n",
    "        Each row of the sparse matrix is the indices of the\n",
    "        indicator vector\n",
    "    * vocab_size: int\n",
    "        This determines the size of the sparse indicator vector\n",
    "    * out_dtype: tf.dtypes.DType\n",
    "        DType of the values of the output tensor\n",
    "    \"\"\"\n",
    "    # create indices of the output sparse tensor\n",
    "    indices = tf.stack([X.indices[:, 0], tf.cast(X.values, tf.int64)], axis=0)\n",
    "    indices = tf.transpose(indices)\n",
    "    # indicator as ones\n",
    "    values = tf.ones_like(X.values)\n",
    "    values = tf.cast(values, out_dtype)\n",
    "    # (batch_size, vocab_size)\n",
    "    dense_shape = (tf.shape(X)[0], vocab_size)\n",
    "\n",
    "    # Make the sparse tensor\n",
    "    y = tf.SparseTensor(\n",
    "        indices=indices,\n",
    "        values=values,\n",
    "        dense_shape=dense_shape\n",
    "    )\n",
    "    y = tf.sparse.reorder(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3aa765c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:15:06.544059Z",
     "start_time": "2023-11-26T05:15:06.527069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 1]\n",
       " [0 2]\n",
       " [0 3]\n",
       " [1 2]\n",
       " [2 0]\n",
       " [2 1]\n",
       " [2 4]], shape=(7, 2), dtype=int64), values=tf.Tensor([1 1 1 1 1 1 1], shape=(7,), dtype=int64), dense_shape=tf.Tensor([3 5], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sparse_to_indicator_tf(X, 5, out_dtype=tf.int64)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a580f3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:15:10.972700Z",
     "start_time": "2023-11-26T05:15:10.957048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int64, numpy=\n",
       "array([[0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 1]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d854d1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:16:04.258750Z",
     "start_time": "2023-11-26T05:16:04.238611Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def sparse_to_indicator_scipy(X, vocab_size, out_dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Convert sparse tensor of indices to vectors of binary indicators\n",
    "\n",
    "    * X:\n",
    "        Each row of the scipy sparse matrix is the indices of the indicator vector\n",
    "    * vocab_size:\n",
    "        This determines the size of the sparse indicator vector\n",
    "    * out_dtype:\n",
    "        DType of the values of the output tensor\n",
    "    \"\"\"\n",
    "    X = coo_matrix(X) # cast to coo_matrix\n",
    "    # configure the sparse matrix\n",
    "    row = np.array(X.row)\n",
    "    col = np.array(X.data, dtype=row.dtype)\n",
    "    data = np.ones_like(col)\n",
    "    shape = (X.shape[0], vocab_size)\n",
    "    # make the sparse matrix\n",
    "    y = coo_matrix((data, (row, col)), shape=shape, dtype=out_dtype)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5a25388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:17:42.885988Z",
     "start_time": "2023-11-26T05:17:42.867533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_coo = coo_matrix(\n",
    "    (X.values.numpy(), (X.indices[:, 0].numpy(), X.indices[:, 1].numpy())), \n",
    "    shape=X.dense_shape.numpy()\n",
    ")\n",
    "y = sparse_to_indicator_scipy(X_coo, 5, out_dtype=int)\n",
    "y.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780261c",
   "metadata": {},
   "source": [
    "# Case Study: Jaccard Similarities Using Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b48b6903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:18:08.467482Z",
     "start_time": "2023-11-26T05:18:08.456079Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def jaccard_similarities(mat):\n",
    "    \"\"\"\n",
    "    Compute pairwise Jaccard similarities\n",
    "    between rows of a coo sparse matrix\n",
    "    \"\"\"\n",
    "    nnz = mat.getnnz(axis=1)\n",
    "    # pair-wise binary intersection |X n Y|\n",
    "    # sparse matrix multiplication\n",
    "    sim = mat * mat.T\n",
    "    sim = sim.astype(float)\n",
    "\n",
    "    # for rows\n",
    "    xx = np.repeat(nnz, sim.getnnz(axis=1))\n",
    "    # for columns\n",
    "    yy = nnz[sim.indices]\n",
    "    \n",
    "    # |X U Y| = |X| + |Y| - |X n Y|\n",
    "    sim.data /= xx + yy - sim.data\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcafa9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:18:17.666020Z",
     "start_time": "2023-11-26T05:18:17.646314Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "mat_dense = np.array([\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 1, 0, 1],\n",
    "])\n",
    "mat = coo_matrix(mat_dense)\n",
    "# Use our implementation\n",
    "sim = jaccard_similarities(mat)\n",
    "\n",
    "# Using for loop and Python native set operations\n",
    "# Convert binary to indices\n",
    "mat_index = []\n",
    "for row in mat_dense:\n",
    "    indices = np.where(row>0)[0].tolist()\n",
    "    mat_index.append(indices)\n",
    "n_items = len(mat_index)    \n",
    "\n",
    "# use set operations to compute jaccard similarity\n",
    "sim_loop = np.zeros((n_items, n_items))\n",
    "for n in range(n_items):\n",
    "    for m in range(n_items):\n",
    "        if m >= n: # only compute the pair once\n",
    "            continue\n",
    "    \n",
    "        x, y = set(mat_index[n]), set(mat_index[m])\n",
    "        sim_loop[n, m] = len(x.intersection(y)) / len(x.union(y))\n",
    "\n",
    "assert np.allclose(np.tril(sim.A, -1), sim_loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abd9df",
   "metadata": {},
   "source": [
    "# Case Study: Batch-wise Set Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fa95708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:18:56.107031Z",
     "start_time": "2023-11-26T05:18:56.088044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0. , 0.5, 0.5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.array([\n",
    "    [False,   True,   True,  False,  False],\n",
    "    [ True,  False,  False,  False,  False],\n",
    "    [False,  False,  False,   True,   True],\n",
    "    [False,   True,   True,  False,  False],\n",
    "])\n",
    "\n",
    "labels = np.array([\n",
    "    [False,   True,   True,  False,  False],\n",
    "    [False,  False,   True,  False,  False],\n",
    "    [ True,  False,  False,   True,  False],\n",
    "    [False,   True,  False,   True,  False],\n",
    "])\n",
    "\n",
    "# Compute true positives: prediction and label both need to be True\n",
    "tp = np.logical_and(predictions, labels)\n",
    "tp = np.sum(tp, axis=1) # count\n",
    "# Compute false positives: prediction is True, label is False\n",
    "fp = np.logical_and(predictions, ~labels)\n",
    "fp = np.sum(fp, axis=1) # count\n",
    "\n",
    "# Compute precision\n",
    "precision = tp / (tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10b6997d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:19:05.209720Z",
     "start_time": "2023-11-26T05:19:05.200188Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = [[1, 2], [0], [3, 4], [1, 2]]\n",
    "labels = [[1, 2], [2], [0, 3], [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddc9fb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:19:17.440209Z",
     "start_time": "2023-11-26T05:19:17.426918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.5, 0.5]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop solution\n",
    "precision = []\n",
    "for pred, lab in zip(predictions, labels):\n",
    "    # true positives\n",
    "    tp = set(pred).intersection(set(lab))\n",
    "    # false positives\n",
    "    fp = set(pred).difference(set(lab))\n",
    "    # precision\n",
    "    p = len(tp) / (len(tp) + len(fp))\n",
    "    precision.append(p)\n",
    "    \n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e470b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:19:43.775550Z",
     "start_time": "2023-11-26T05:19:43.749868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([1. , 0. , 0.5, 0.5])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# Create the left-aligned ragged sparse tensors\n",
    "predictions = tf.ragged.constant([[1, 2], [0], [3, 4], [1, 2]]).to_sparse()\n",
    "labels = tf.ragged.constant([[1, 2], [2], [0, 3], [1, 3]]).to_sparse()\n",
    "# Compute true positives\n",
    "tp = tf.sets.intersection(predictions, labels)\n",
    "tp = tf.sets.size(tp) # count each row\n",
    "# Compute false positives\n",
    "fp = tf.sets.difference(predictions, labels)\n",
    "fp = tf.sets.size(fp) # count each row\n",
    "# Compute precisions\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0d2b29c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:19:57.988468Z",
     "start_time": "2023-11-26T05:19:57.969110Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "def set_operation(x, y, pad=None, operation=\"intersection\", returns=\"count\"):\n",
    "    \"\"\"\n",
    "    Batch-wise set operations.\n",
    "    \n",
    "    Inputs:\n",
    "        * x, y: dense 2D np.ndarrays with/without padding values.\n",
    "        * pad: padding values. Default to None which is no padding.\n",
    "        * operation: set operation to perform. Valid values are\n",
    "            [\"intersection\" (default), \"union\", \"difference\"].\n",
    "        * returns: type of returned outputs, either \"count\" (default) which \n",
    "            counts the cardinality of the resulting set operation for each \n",
    "            row or \"matrix\" which returns the sparse matrix output from\n",
    "            the set operations, all values are left aligned.\n",
    "    \"\"\"\n",
    "    # Input shapes\n",
    "    n_d, m_x = x.shape\n",
    "    n_d, m_y = y.shape\n",
    "\n",
    "    # Use np.unique to create convert from data -> indices\n",
    "    # This can appropriately handle all data types, including strings\n",
    "    unique, indices = np.unique(np.hstack((x, y)), return_inverse=True)\n",
    "    n_unique = len(unique)\n",
    "    \n",
    "    # From flattened index -> original shape\n",
    "    indices = indices.reshape(n_d, -1)\n",
    "    indices_x = indices[:, :m_x]\n",
    "    indices_y = indices[:, m_x:]\n",
    "    \n",
    "    # which index from unique is the padding of the ragged representation\n",
    "    pad_index = np.where(unique == pad)[0]\n",
    "    if len(pad_index) > 0: # found the padding\n",
    "        pad_index = pad_index[0]\n",
    "    else:\n",
    "        pad_index = -1\n",
    "    \n",
    "    # Use csr format to create to create binary indicator matrices\n",
    "    # e.g. index = [1, 3], n_unique = 5 -> [0, 1, 0, 1, 0]\n",
    "    def _create_csr_indicator(idx, m):\n",
    "        # create csr\n",
    "        indptr = np.repeat([m], n_d).cumsum()\n",
    "        indptr = np.concatenate([[0], indptr])\n",
    "        indices = idx.ravel() # flatten\n",
    "        data = np.ones_like(indices, dtype=int)\n",
    "        data[indices==pad_index] = 0 # filter out pad index\n",
    "        sparse_matrix = csr_matrix(\n",
    "            (data, indices, indptr), shape=(n_d, n_unique), dtype=int\n",
    "        )\n",
    "        # eliminate padding if any\n",
    "        sparse_matrix.eliminate_zeros()\n",
    "        return sparse_matrix\n",
    "    \n",
    "    x_hat = _create_csr_indicator(indices_x, m_x)\n",
    "    y_hat = _create_csr_indicator(indices_y, m_y)\n",
    "    \n",
    "    # set operations using binary arithmetic operation\n",
    "    if operation == \"intersection\":\n",
    "        res = x_hat.multiply(y_hat)\n",
    "    elif operation == \"union\":\n",
    "        res = x_hat + y_hat\n",
    "        res.data = np.minimum(res.data, 1)\n",
    "    elif operation == \"difference\":\n",
    "        res = x_hat - y_hat\n",
    "        res.data = np.maximum(res.data, 0)\n",
    "    else:\n",
    "        raise(ValueError(f\"Unrecognized operation {operation}\"))\n",
    "        \n",
    "    if returns == \"count\": # return cardinality of set\n",
    "        return res.sum(axis=1).A.ravel()\n",
    "    else: # return the actual sparse matrix\n",
    "        # keep only entries of 1s\n",
    "        res.eliminate_zeros()\n",
    "        # replace the indicator back to actual intersected values\n",
    "        res.data = np.take(unique, res.indices)\n",
    "        # left align\n",
    "        l = np.diff(res.indptr) # array lengths\n",
    "        flat_indices = np.arange(len(res.data))\n",
    "        offsets = np.repeat(res.indptr[:-1], l)\n",
    "        res.indices = flat_indices - offsets\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63c39755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:20:28.929571Z",
     "start_time": "2023-11-26T05:20:28.913120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0. , 0.5, 0.5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array([[1, 2], [0, -1], [3, 4], [1, 2]])\n",
    "labels = np.array([[1, 2], [2, -1], [0, 3], [1, 3]])\n",
    "tp = set_operation(predictions, labels, -1, operation=\"intersection\")\n",
    "fp = set_operation(predictions, labels, -1, operation=\"difference\")\n",
    "precision = tp / (tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da89017",
   "metadata": {},
   "source": [
    "Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c73f01e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:21:46.027884Z",
     "start_time": "2023-11-26T05:21:46.015490Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use IPython magic function to measure performance\n",
    "x = np.array([\n",
    "    [1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 5, 1, 0, 0]\n",
    "]*1024)\n",
    "y = np.array([\n",
    "    [5, 6, 7, 8, 9], [2, 3, 5, 7, 8], [3, 1, 0, 0, 0]\n",
    "]*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5d8ff9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:21:57.115087Z",
     "start_time": "2023-11-26T05:21:48.834336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01 ms ± 21.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Our NumPy implementation\n",
    "%timeit res_np = set_operation(x, y, operation=\"intersection\", pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "234ecd9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:22:07.838548Z",
     "start_time": "2023-11-26T05:22:07.803460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python For Loop\n",
    "def batch_wise_intersection(x, y, pad=None):\n",
    "    batch_size = x.shape[0]\n",
    "    res = [[]] * batch_size\n",
    "    for ii in range(batch_size):\n",
    "        # take intersection\n",
    "        r = set(x[ii, :]).intersection(set(y[ii, :]))\n",
    "        if pad is not None:\n",
    "            # remove padding\n",
    "            r = r.difference(set([pad]))\n",
    "        res[ii] = len(r)\n",
    "        \n",
    "    return res\n",
    "\n",
    "res_python = batch_wise_intersection(x, y, pad=0)\n",
    "res_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ad7b052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:22:16.928521Z",
     "start_time": "2023-11-26T05:22:13.426573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.27 ms ± 30.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit res_python = batch_wise_intersection(x, y, pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c11ac7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:22:45.165530Z",
     "start_time": "2023-11-26T05:22:35.527136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 ms ± 20.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Use Tensorflow tf.sets.intersection\n",
    "%timeit res_tf = tf.sets.size(tf.sets.intersection(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8dd91",
   "metadata": {},
   "source": [
    "# Case Study: Autoencoders with Sparse Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3395aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:23:47.786856Z",
     "start_time": "2023-11-26T05:23:47.763046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[11, 13, 15]], dtype=int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparse dense multiplication (Tensorflow)\n",
    "import tensorflow as tf\n",
    "x = tf.sparse.from_dense([[0, 1, 1, 0, 0]])\n",
    "W = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 3, 5],\n",
    "    [2, 4, 6],\n",
    "])\n",
    "y_tilde = tf.sparse.sparse_dense_matmul(x, W)\n",
    "y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f472227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:24:14.265322Z",
     "start_time": "2023-11-26T05:24:14.235182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 13, 15]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparse dense multiplication (PyTorch)\n",
    "import torch\n",
    "x = torch.tensor([[0, 1, 1, 0, 0]]).to_sparse()\n",
    "W = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 3, 5],\n",
    "    [2, 4, 6],\n",
    "])\n",
    "y_tilde = torch.sparse.mm(x, W)\n",
    "y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee3720e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:24:38.102308Z",
     "start_time": "2023-11-26T05:24:38.077127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[11, 13, 15],\n",
       "       [ 4,  9, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using embedding lookup (Tensorflow)\n",
    "import tensorflow as tf\n",
    "\n",
    "s = tf.ragged.constant([[1, 2], [3, 0, 4]]).to_sparse()\n",
    "W = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 3, 5],\n",
    "    [2, 4, 6],\n",
    "])\n",
    "weights = s.with_values(tf.ones_like(s.values)) # equal weights\n",
    "y_tilde = tf.nn.embedding_lookup_sparse(\n",
    "    W,\n",
    "    s,\n",
    "    weights,\n",
    "    combiner=\"sum\",\n",
    ")\n",
    "y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee7b8cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:25:15.057057Z",
     "start_time": "2023-11-26T05:25:15.028990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 13, 15],\n",
       "        [ 4,  9, 14]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using embedding lookup (PyTorch)\n",
    "import torch\n",
    "\n",
    "# 1-based indexing; 0 is used as padding index\n",
    "s = torch.tensor([[2, 3, 0, 0, 0], [4, 1, 5, 0, 0]])\n",
    "W = torch.tensor([\n",
    "    [0, 0, 0], # padding entry\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 3, 5],\n",
    "    [2, 4, 6],\n",
    "])\n",
    "\n",
    "y_tilde = torch.nn.functional.embedding(\n",
    "    s,\n",
    "    W,\n",
    "    padding_idx=0,\n",
    ").sum(dim=1)\n",
    "y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b301eaff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:25:51.746473Z",
     "start_time": "2023-11-26T05:25:51.724137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[24.099998, 28.1     , 32.100002],\n",
       "       [ 8.3     , 18.7     , 29.099998]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted embedding lookup (Tensorflow)\n",
    "import tensorflow as tf\n",
    "\n",
    "s = tf.ragged.constant([[1, 2], [3, 0, 4]]).to_sparse()\n",
    "v = tf.ragged.constant([[1.3, 2.7], [2.1, 4.6, 0.8]]).to_sparse()\n",
    "W = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 3, 5],\n",
    "    [2, 4, 6],\n",
    "], dtype=tf.float32)\n",
    "y_tilde = tf.nn.embedding_lookup_sparse(\n",
    "    W,\n",
    "    s,\n",
    "    v,\n",
    "    combiner=\"sum\",\n",
    ")\n",
    "y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee927578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:26:24.386088Z",
     "start_time": "2023-11-26T05:26:24.355319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24.1000, 28.1000, 32.1000],\n",
       "        [ 8.3000, 18.7000, 29.1000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted embedding lookup (PyTorch)\n",
    "import torch\n",
    "\n",
    "# 1-based indexing; 0 is used as padding index\n",
    "s = torch.tensor([[2, 3, 0, 0, 0], [4, 1, 5, 0, 0]])\n",
    "# using dense representations with paddings\n",
    "v = torch.tensor([[1.3, 2.7, 0.0, 0.0, 0.0], [2.1, 4.6, 0.8, 0.0, 0.0]])\n",
    "W = torch.tensor([\n",
    "    [0, 0, 0], # padding entry\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 3, 5],\n",
    "    [2, 4, 6],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# look up embeddings\n",
    "y_tilde = torch.nn.functional.embedding(\n",
    "    s,\n",
    "    W,\n",
    "    padding_idx=0,\n",
    ")\n",
    "# apply weights\n",
    "y_tilde *= v[:, :, None]\n",
    "# Combine\n",
    "y_tilde = y_tilde.sum(dim=1)\n",
    "y_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5108ec7",
   "metadata": {},
   "source": [
    "### Autoencoder with sparse inputs\n",
    "\n",
    "Tensorflow / Keras version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7efe871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:26:51.086005Z",
     "start_time": "2023-11-26T05:26:51.062335Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import Model, Input\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    \"\"\"Autoencoder with sparse inputs.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items,\n",
    "        emb_size,\n",
    "        hidden_activation=\"relu\",\n",
    "        output_activation=\"sigmoid\",\n",
    "    ):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_activation = Activation(\n",
    "            hidden_activation, name=\"hidden_activation\"\n",
    "        )\n",
    "        self.output_layer = Dense(num_items, name=\"output_layer\")\n",
    "        self.output_activation = Activation(\n",
    "            output_activation, name=\"output_activation\"\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = self.add_weight(\n",
    "            name=\"embedding\",\n",
    "            shape=(self.num_items, self.emb_size),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\",\n",
    "            shape=(1, self.emb_size),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        items = inputs[\"items\"]\n",
    "        weights = inputs.get(\"weights\", None)\n",
    "        if weights is None:\n",
    "            # equal weights\n",
    "            weights = items.with_value(tf.ones_like(items, tf.float32))\n",
    "\n",
    "        # Implement the sparse dense layer (batch_size, emb_size)\n",
    "        embed = tf.nn.embedding_lookup_sparse(\n",
    "            self.embedding, items, weights, combiner=\"sum\", name=\"hidden_embed\"\n",
    "        )\n",
    "\n",
    "        # Add bias\n",
    "        y = embed + self.bias\n",
    "\n",
    "        # Hidden layer activation\n",
    "        y = self.hidden_activation(y)\n",
    "\n",
    "        # Decode to produce output\n",
    "        z = self.output_layer(y)\n",
    "        z = self.output_activation(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        inputs = {\n",
    "            \"items\": Input((None,), sparse=True, dtype=tf.int64, name=\"items\"),\n",
    "            \"weights\": Input(\n",
    "                (None,), sparse=True, dtype=tf.float32, name=\"weights\"\n",
    "            ),\n",
    "        }\n",
    "        model = Model(inputs, self.call(inputs))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "148a165a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:27:27.921227Z",
     "start_time": "2023-11-26T05:27:27.867933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1000), dtype=float32, numpy=\n",
       "array([[0.49876222, 0.49345723, 0.5265454 , ..., 0.4920722 , 0.49508202,\n",
       "        0.49603644],\n",
       "       [0.4880186 , 0.50813854, 0.50340515, ..., 0.5355486 , 0.49567267,\n",
       "        0.48957598]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"items\": tf.ragged.constant([[1, 2], [3, 0, 4]]).to_sparse(),\n",
    "    \"weights\": tf.ragged.constant([[1.3, 2.7], [2.1, 4.6, 0.8]]).to_sparse(),\n",
    "}\n",
    "\n",
    "model = Autoencoder(num_items=1000, emb_size=128)\n",
    "z = model(inputs) # use the input to produce output, (2, 1000)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb20d9e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:27:37.499224Z",
     "start_time": "2023-11-26T05:27:37.443059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_sparse), but are not present in its tracked objects:   <tf.Variable 'autoencoder/embedding:0' shape=(1000, 128) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add), but are not present in its tracked objects:   <tf.Variable 'autoencoder/bias:0' shape=(1, 128) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " items (InputLayer)          [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " weights (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.nn.embedding_  (None, 128)                  0         ['items[0][0]',               \n",
      " lookup_sparse (TFOpLambda)                                          'weights[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 128)                  0         ['tf.compat.v1.nn.embedding_lo\n",
      " Lambda)                                                            okup_sparse[0][0]']           \n",
      "                                                                                                  \n",
      " hidden_activation (Activat  (None, 128)                  0         ['tf.__operators__.add[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " output_layer (Dense)        (None, 1000)                 129000    ['hidden_activation[0][0]']   \n",
      "                                                                                                  \n",
      " output_activation (Activat  (None, 1000)                 0         ['output_layer[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 129000 (503.91 KB)\n",
      "Trainable params: 129000 (503.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad66c37",
   "metadata": {},
   "source": [
    "PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "124ea273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:27:52.900193Z",
     "start_time": "2023-11-26T05:27:52.880846Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, num_items, emb_size):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(\n",
    "            num_items, emb_size, padding_idx=0\n",
    "        )\n",
    "        self.bias = torch.nn.Parameter(torch.zeros([1, emb_size])) \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(emb_size, num_items),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, items, weights=None):\n",
    "        if weights is None:\n",
    "            # equal weights\n",
    "            weights = torch.ones([items.shape[0], 1], dtype=torch.float32)\n",
    "        \n",
    "        # Implement the sparse dense layer (batch_size, emb_size)\n",
    "        embed = self.embed(items)\n",
    "        # Apply weights\n",
    "        embed *= weights[:, :, None]\n",
    "        # Sum together embeddings\n",
    "        embed = embed.sum(dim=1)\n",
    "\n",
    "        # Add bias\n",
    "        y = embed + self.bias\n",
    "\n",
    "        # Hidden layer activation\n",
    "        z = self.decoder(y)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2b8811c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:28:21.941673Z",
     "start_time": "2023-11-26T05:28:21.913061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5380, 0.2701, 0.2039,  ..., 0.6616, 0.0411, 0.7240],\n",
       "        [0.7360, 0.5025, 0.4160,  ..., 0.5767, 0.1092, 0.4250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"items\": torch.tensor([[2, 3, 0], [4, 1, 5]]),\n",
    "    \"weights\": torch.tensor([[1.3, 2.7, 0.0], [2.1, 4.6, 0.8]]),\n",
    "}\n",
    "\n",
    "model = Autoencoder(num_items=1000, emb_size=128)\n",
    "z = model(**inputs)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0153c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T05:28:29.396086Z",
     "start_time": "2023-11-26T05:28:29.387728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (embed): Embedding(1000, 128, padding_idx=0)\n",
      "  (decoder): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=128, out_features=1000, bias=True)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
